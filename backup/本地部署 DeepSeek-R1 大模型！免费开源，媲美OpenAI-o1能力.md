æœ€è¿‘ï¼Œä¸€å®¶åå«DeepSeekçš„åˆåˆ›å…¬å¸ç»è¿‡æŠ€æœ¯è¿­ä»£ä¸å‡çº§ï¼Œå‘å¸ƒäº†å…¨æ–°ä¸€ä»£å¤§æ¨¡å‹ï¼Œâ€œDeepSeek-V3â€ã€‚ç”±äºè¿™æ¬¾å¤§æ¨¡å‹å¤ªè¿‡å¥½ç”¨ï¼ŒDeepSeek R1 æ›´æ˜¯ç›´æ¥å…è´¹å¼€æºï¼Œåœ¨AIå‘çƒ§å‹åœˆå­ä¼ æ’­åï¼Œä¼ åˆ°äº†æµ·å¤–ç¤¾äº¤å¹³å°ã€æŠ€æœ¯è®ºå›ï¼Œå¼•å‘äº†æµ·å¤–ç½‘å‹çš„è¿è¿ç§°èµã€‚

![](https://www.freedidi.com/wp-content/uploads/2025/01/0ca1c0838c20250125140830.webp)

å„é¡¹æ€§èƒ½æŒ‡æ ‡æ›´æ˜¯å’ŒOpenAI-o1 æ¨¡å‹ä¸ç›¸ä¸Šä¸‹ï¼Œç”šè‡³åšåˆ°äº†å°éƒ¨åˆ†çš„è¶…è¶Šï¼Œå…³é”®æ˜¯å¼€æºçš„ï¼Œæˆ‘ä»¬å¯ä»¥æœ¬åœ°éƒ¨ç½²ä½¿ç”¨

**1ã€æœ¬åœ°éƒ¨ç½²ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡Ollamaæ¥è¿›è¡Œå®‰è£…**
Ollama å®˜æ–¹ç‰ˆï¼šã€[ç‚¹å‡»å‰å¾€](https://ollama.com/)ã€‘
Web UI æ§åˆ¶ç«¯ã€[ç‚¹å‡»å®‰è£…](https://chromewebstore.google.com/detail/page-assist-%E6%9C%AC%E5%9C%B0-ai-%E6%A8%A1%E5%9E%8B%E7%9A%84-web/jfgfiigpkhlkbnfnbobbkinehhfdhndo)ã€‘

å®‰è£…å‘½ä»¤

1.5B Qwen DeepSeek R1
```
ollama run deepseek-r1:1.5b
```
7B Qwen DeepSeek R1
```
ollama run deepseek-r1:7b
```
8B Llama DeepSeek R1
```
ollama run deepseek-r1:8b
```
14B Qwen DeepSeek R1
```
ollama run deepseek-r1:14b
```
32B Qwen DeepSeek R1
```
ollama run deepseek-r1:14b
```
70B Llama DeepSeek R1
```
ollama run deepseek-r1:70b
```

**2.How to run**

List models on your computer
```
ollama list
```
Show model information
```
ollama show example
```
Run the model
```
ollama run example
```
Remove a model
```
ollama rm example
```

**3. Model library**

Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library)
Here are some example models that can be downloaded:


Model | Parameters | Size | Download
-- | -- | -- | --
Llama 3.3 | 70B | 43GB | ollama run llama3.3
Llama 3.2 | 3B | 2.0GB | ollama run llama3.2
Llama 3.2 | 1B | 1.3GB | ollama run llama3.2:1b
Llama 3.2 Vision | 11B | 7.9GB | ollama run llama3.2-vision
Llama 3.2 Vision | 90B | 55GB | ollama run llama3.2-vision:90b
Llama 3.1 | 8B | 4.7GB | ollama run llama3.1
Llama 3.1 | 405B | 231GB | ollama run llama3.1:405b
Phi 4 | 14B | 9.1GB | ollama run phi4
Phi 3 Mini | 3.8B | 2.3GB | ollama run phi3
Gemma 2 | 2B | 1.6GB | ollama run gemma2:2b
Gemma 2 | 9B | 5.5GB | ollama run gemma2
Gemma 2 | 27B | 16GB | ollama run gemma2:27b
Mistral | 7B | 4.1GB | ollama run mistral
Moondream 2 | 1.4B | 829MB | ollama run moondream
Neural Chat | 7B | 4.1GB | ollama run neural-chat
Starling | 7B | 4.1GB | ollama run starling-lm
Code Llama | 7B | 3.8GB | ollama run codellama
Llama 2 Uncensored | 7B | 3.8GB | ollama run llama2-uncensored
LLaVA | 7B | 4.5GB | ollama run llava
Solar | 10.7B | 6.1GB | ollama run solar

DeepSeek-R1

æ¨¡å‹ | #æ€»å‚æ•° | #å·²æ¿€æ´»å‚æ•° | ä¸Šä¸‹æ–‡é•¿åº¦ | ä¸‹è½½
-- | -- | -- | -- | --
DeepSeek-R1-Zero | 671B | 37B | 128åƒ | ğŸ¤— HuggingFace
DeepSeek-R1 | 671B | 37B | 128åƒ | ğŸ¤— HuggingFace

DeepSeek-R1-Zero å’Œ DeepSeek-R1 åŸºäº DeepSeek-V3-Base è¿›è¡Œè®­ç»ƒã€‚æœ‰å…³æ¨¡å‹æ¶æ„çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3)å­˜å‚¨åº“ã€‚

DeepSeek-R1-Distill æ¨¡å‹

æ¨¡å‹ | åŸºç¡€æ¨¡å‹ | ä¸‹è½½
-- | -- | --
DeepSeek-R1-Distill-Qwen-1.5B | Qwen2.5-Math-1.5B | ğŸ¤— HuggingFace
DeepSeek-R1-Distill-Qwen-7B | Qwen2.5-Math-7B | ğŸ¤— HuggingFace
DeepSeek-R1-Distill-Llama-8B | Llama-3.1-8B | ğŸ¤— HuggingFace
DeepSeek-R1-Distill-Qwen-14B | Qwen2.5-14B | ğŸ¤— HuggingFace
DeepSeek-R1-Distill-Qwen-32B | Qwen2.5-32B | ğŸ¤— HuggingFace
DeepSeek-R1-Distill-Llama-70B | Llama-3.3-70B-Instruct | ğŸ¤— HuggingFace

DeepSeek-R1-Distill æ¨¡å‹åŸºäºå¼€æºæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿ç”¨äº† DeepSeek-R1 ç”Ÿæˆçš„æ ·æœ¬ã€‚æˆ‘ä»¬å¯¹å…¶é…ç½®å’Œåˆ†è¯å™¨è¿›è¡Œäº†è½»å¾®æ›´æ”¹ã€‚è¯·ä½¿ç”¨æˆ‘ä»¬çš„è®¾ç½®æ¥è¿è¡Œè¿™äº›æ¨¡å‹ã€‚

**4.è¯„ä¼°ç»“æœ**
DeepSeek-R1-è¯„ä¼°
å¯¹äºæˆ‘ä»¬æ‰€æœ‰çš„æ¨¡å‹ï¼Œæœ€å¤§ç”Ÿæˆé•¿åº¦è®¾ç½®ä¸º 32,768 ä¸ª tokenã€‚å¯¹äºéœ€è¦é‡‡æ ·çš„åŸºå‡†ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ¸©åº¦ä¸º0.6ï¼Œtop-p å€¼ä¸º0.95ï¼Œå¹¶ä¸ºæ¯ä¸ªæŸ¥è¯¢ç”Ÿæˆ 64 ä¸ªå“åº”æ¥ä¼°è®¡ pass@1ã€‚

ç±»åˆ« | åŸºå‡†ï¼ˆå…¬åˆ¶ï¼‰ | å…‹åŠ³å¾·-3.5-åå››è¡Œè¯—-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217 | DeepSeek R1
-- | -- | -- | -- | -- | -- | -- | --
Â  | å»ºç­‘å­¦ | â€“ | â€“ | æ•™è‚²éƒ¨ | â€“ | â€“ | æ•™è‚²éƒ¨
Â  | # æ¿€æ´»å‚æ•° | â€“ | â€“ | 37B | â€“ | â€“ | 37B
Â  | # æ€»å‚æ•° | â€“ | â€“ | 671B | â€“ | â€“ | 671B
è‹±è¯­ | MMLUï¼ˆé€šè¿‡@1ï¼‰ | 88.3 | 87.2 | 88.5 | 85.2 | 91.8 | 90.8
Â  | MMLU-Reduxï¼ˆEMï¼‰ | 88.9 | 88.0 | 89.1 | 86.7 | â€“ | 92.9
Â  | MMLU-Proï¼ˆEMï¼‰ | 78.0 | 72.6 | 75.9 | 80.3 | â€“ | 84.0
Â  | æ‰è½ (3 å‘ F1) | 88.3 | 83.7 | 91.6 | 83.9 | 90.2 | 92.2
Â  | IF-Evalï¼ˆæç¤ºä¸¥æ ¼ï¼‰ | 86.5 | 84.3 | 86.1 | 84.8 | â€“ | 83.3
Â  | GPQA-é’»çŸ³çº§ (Pass@1) | 65.0 | 49.9 | 59.1 | 60.0 | 75.7 | 71.5
Â  | SimpleQAï¼ˆæ­£ç¡®ï¼‰ | 28.4 | 38.2 | 24.9 | 7.0 | 47.0 | 30.1
Â  | æ¡†æ¶ï¼ˆé…ä»¶ï¼‰ | 72.5 | 80.5 | 73.3 | 76.9 | â€“ | 82.5
Â  | AlpacaEval2.0 (LC-èƒœç‡) | 52.0 | 51.1 | 70.0 | 57.8 | â€“ | 87.6
Â  | ArenaHardï¼ˆGPT-4-1106ï¼‰ | 85.2 | 80.4 | 85.5 | 92.0 | â€“ | 92.3
ä»£ç  | LiveCodeBench (Pass@1-COT) | 33.8 | 34.2 | â€“ | 53.8 | 63.4 | 65.9
Â  | Codeforcesï¼ˆç™¾åˆ†ä½æ•°ï¼‰ | 20.3 | 23.6 | 58.7 | 93.4 | 96.6 | 96.3
Â  | Codeforcesï¼ˆè¯„çº§ï¼‰ | 717 | 759 | 1134 | 1820 | 2061 | 2029
Â  | SWE å·²éªŒè¯ï¼ˆå·²è§£å†³ï¼‰ | 50.8 | 38.8 | 42.0 | 41.6 | 48.9 | 49.2
Â  | Aider-Polyglot (Acc.) | 45.3 | 16.0 | 49.6 | 32.9 | 61.7 | 53.3
æ•°å­¦ | AIME 2024ï¼ˆé€šè¡Œè¯@1ï¼‰ | 16.0 | 9.3 | 39.2 | 63.6 | 79.2 | 79.8
Â  | æ•°å­¦-500 (é€šè¿‡@1) | 78.3 | 74.6 | 90.2 | 90.0 | 96.4 | 97.3
Â  | CNMO 2024 (é€šè¡Œè¯@1) | 13.1 | 10.8 | 43.2 | 67.6 | â€“ | 78.8
ä¸­æ–‡ | CLUEWSCï¼ˆEMï¼‰ | 85.4 | 87.9 | 90.9 | 89.9 | â€“ | 92.8
Â  | C-è¯„ä¼°ï¼ˆEMï¼‰ | 76.7 | 76.0 | 86.5 | 68.9 | â€“ | 91.8
Â  | C-SimpleQAï¼ˆæ­£ç¡®ï¼‰ | 55.4 | 58.7 | 68.0 | 40.3 | â€“ | 63.7

è’¸é¦æ¨¡å‹è¯„ä¼°

æ¨¡å‹ | AIME 2024 é€šè¡Œè¯@1 | AIME 2024 ç¼ºç‚¹@64 | MATH-500 é€šè¿‡@1 | GPQA é’»çŸ³é€šè¡Œè¯@1 | LiveCodeBench é€šè¡Œè¯@1 | CodeForces è¯„çº§
-- | -- | -- | -- | -- | -- | --
GPT-4o-0513 | 9.3 | 13.4 | 74.6 | 49.9 | 32.9 | 759
å…‹åŠ³å¾·-3.5-åå››è¡Œè¯—-1022 | 16.0 | 26.7 | 78.3 | 65.0 | 38.9 | 717
o1-è¿·ä½  | 63.6 | 80.0 | 90.0 | 60.0 | 53.8 | 1820
QwQ-32B-é¢„è§ˆ | 44.0 | 60.0 | 90.6 | 54.5 | 41.9 | 1316
DeepSeek-R1-Distill-Qwen-1.5B | 28.9 | 52.7 | 83.9 | 33.8 | 16.9 | 954
DeepSeek-R1-Distill-Qwen-7B | 55.5 | 83.3 | 92.8 | 49.1 | 37.6 | 1189
DeepSeek-R1-Distill-Qwen-14B | 69.7 | 80.0 | 93.9 | 59.1 | 53.1 | 1481
DeepSeek-R1-Distill-Qwen-32B | 72.6 | 83.3 | 94.3 | 62.1 | 57.2 | 1691
DeepSeek-R1-Distill-Llama-8B | 50.4 | 80.0 | 89.1 | 49.0 | 39.6 | 1205
DeepSeek-R1-Distill-Llama-70B | 70.0 | 86.7 | 94.5 | 65.2 | 57.5 | 1633


