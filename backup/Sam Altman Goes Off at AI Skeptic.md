In the artificial intelligence world, there are two streams. One is the cool, analytical current of AI scholarship, flowing with genuine curiosity and drive to verify. The other is the boiling-hot torrent of commercial AI — excited, frenetic, gushing with utopian promises.

As AI hype blasts off into the heavens, one notable tech critic asks an important question: which of these streams should drive AI development?

Yesterday, neural scientist, AI scholar and outspoken OpenAI critic Gary Marcus took to X-formerly-Twitter to blast OpenAI CEO Sam Altman's brand of incessant AI hype.

"Sam keeps doubling down on bigger and bigger promises that are harder to keep," Marcus wrote. "Did Elizabeth Holmes do the same?"

The post was accompanied by a picture of Altman's head superimposed over a portrait of the infamous conwoman, whose $9 billion blood-testing company Theranos collapsed after investigators discovered its leaders had deceived investors by wildly overhyping their tech's abilities.

Marcus' comment came just hours after Altman published a characteristically strident essay, "The Gentle Singularity," in which he claims that "humanity is close to building digital superintelligence" — something which a lot of experts in the space say is patently false.

Altman bit back in response, fuming that he respects Marcus' "commitment to the bit." Marcus is a longtime critic of Altman's chosen model of AI production, "scaling," where tech companies dump untold billions into ever-larger systems powered by more processing power and larger quantities of data, scraped without the permission of its original creators.

Though Altman projects nothing but confidence, the strategy's long-term prospects remain divisive. It took a hit earlier this year, for instance, when Chinese company DeepSeek released a large language model (LLM) roughly equal to OpenAI's ChatGPT, developed for a fraction of the cost.

"Can't tell if he is a troll or just extremely intellectually dishonest," Altman continued in his broadside against Marcus. "Hundreds of millions of happy users, 5th biggest website in the world, people talking about it being the biggest change to their productivity ever... we deliver, he keeps ordering us off his lawn."

For his part, Marcus says he has no problem with OpenAI's commercial achievements, per se.

"I would be singing OpenAI's praises," the critic replied, "if it weren’t for the hype, much of it fanned by you, that has massively overstated what the technology can do today and in the near future."

If one could summarize Marcus' contention, it might be said that one can either be a rigorous AI scholar, or a billionaire tech emperor — but not both.

"I think this hype is harming the world," he said.

Altman's deep desire to be an AI thought leader — complete with bizarre pseudo-manifestos — is constantly putting him at odds with his tech dynasty, as his endless promises of "superintelligence," "solving physics," and "superhuman reasoning" make clear. The drive to hype his brand, not to mention his personal image, is constantly leading him to fantastic conclusions that fewer serious researchers would indulge, like the playground fantasy that functional humanoid robots "aren't very far away."

This conflict also leads him to make unforced errors in real life, such as reversing course on OpenAI's long-stated open source development model, and backtracking on his stance supporting strong AI regulation — something he and Marcus once stood side by side on, literally.

Which of the two streams ultimately wins out will be decided in the years to come. For now, it seems commercial AI — and all the hype that follows — is dominating the conversation, though whether it can keep its lead as the financial losses mount is anyone's guess.